{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of the Beam model\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "![image](https://beam.apache.org/images/design-your-pipeline-multiple-pcollections.svg)\n",
    "\n",
    "* **Pipeline** - A pipeline is a user-constructed graph of transformations that defines the desired data processing operations.\n",
    "* **PCollection** - A PCollection is a data set or data stream. The data that a pipeline processes is part of a PCollection.\n",
    "* **PTransform** - A PTransform (or transform) represents a data processing operation, or a step, in your pipeline. A transform is applied to zero or more PCollection objects, and produces zero or more PCollection objects.\n",
    "* **Aggregation** - Aggregation is computing a value from multiple (1 or more) input elements.\n",
    "* **User** -defined function (UDF) - Some Beam operations allow you to run user-defined code as a way to configure the transform.\n",
    "* **Schema** - A schema is a language-independent type definition for a PCollection. The schema for a PCollection defines elements of that PCollection as an ordered list of named fields.\n",
    "* **SDK** - A language-specific library that lets pipeline authors build transforms, construct their pipelines, and submit them to a runner.\n",
    "* **Runner** - A runner runs a Beam pipeline using the capabilities of your chosen data processing engine.\n",
    "* **Window** - A PCollection can be subdivided into windows based on the timestamps of the individual elements. Windows enable grouping operations over collections that grow over time by dividing the collection into windows of finite collections.\n",
    "* **Watermark** - A watermark is a guess as to when all data in a certain window is expected to have arrived. This is needed because data isnâ€™t always guaranteed to arrive in a pipeline in time order, or to always arrive at predictable intervals.\n",
    "* **Trigger** - A trigger determines when to aggregate the results of each window.\n",
    "* **State and timers** - Per-key state and timer callbacks are lower level primitives that give you full control over aggregating input collections that grow over time.\n",
    "* **Splittable DoFn** - Splittable DoFns let you process elements in a non-monolithic way. You can checkpoint the processing of an element, and the runner can split the remaining work to yield additional parallelism.\n",
    "\n",
    "> more info on the [link](https://beam.apache.org/documentation/basics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps\n",
    "\n",
    "## Import Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting interactivity options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.options.recording_duration = '10m'\n",
    "# Set the recording size limit to 1 GB.\n",
    "ib.options.recording_size_limit = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a PCollection from in-memory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = p | beam.Create([1,2,3,4])\n",
    "ib.show(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (\n",
    "      p\n",
    "      | beam.Create([\n",
    "          'To be, or not to be: that is the question: ',\n",
    "          \"Whether 'tis nobler in the mind to suffer \",\n",
    "          'The slings and arrows of outrageous fortune, ',\n",
    "          'Or to take arms against a sea of troubles, ',\n",
    "      ]))\n",
    "ib.show(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from an external source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = p | 'ReadMyFile' >> beam.io.ReadFromText('./my_text.txt')\n",
    "ib.show(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common structure of a Pipeline\n",
    "\n",
    "![image1](pipe.svg)\n",
    "\n",
    "![image2](DoFn.svg)\n",
    "\n",
    "[Python transform catalog overview](https://beam.apache.org/documentation/transforms/python/overview/)\n",
    "\n",
    "[Built-in I/O Transforms](https://beam.apache.org/documentation/io/built-in/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a first transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeWordLengthFn(beam.DoFn):\n",
    "  def process(self, element):\n",
    "    return [len(element)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying transforms\n",
    "\n",
    "![image](https://beam.apache.org/images/design-your-pipeline-linear.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lengths = lines | beam.ParDo(ComputeWordLengthFn())\n",
    "ib.show(word_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Big Data Analytics: An Interactive Introduction to Apache Beam](https://www.youtube.com/watch?v=w0L1rjU_Ib4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
